# Train via command line
NCCL_TIMEOUT=3600 TORCH_DISTRIBUTED_TIMEOUT=3600 accelerate launch --config_file=recipes/accelerate_configs/zero3.yaml src/open_r1/sft.py \
    --model_name_or_path allenai/OLMo-2-1124-7B \
    --dataset_name open-r1/OpenR1-Math-220k \
    --learning_rate 1.0e-5 \
    --num_train_epochs 1 \
    --max_seq_length 256 \
    --per_device_train_batch_size 1 \
    --gradient_checkpointing \
    --bf16 \
    --output_dir data/allenai/OLMo-2-1124-7B-Open-R1-Distill \
    --dataloader_num_workers 16 \
    --gradient_accumulation_steps 8 \
    --max_steps 20000

# Train via YAML config
accelerate launch --config_file recipes/accelerate_configs/zero3.yaml src/open_r1/sft.py \
    --config recipes/allenai/OLMo-2-1124-7B-Instruct/sft/config_demo.yaml